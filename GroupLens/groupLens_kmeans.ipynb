{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Instalation of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to have the progress bar\n",
    "!pip install tqdm\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Get all files needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../Dataset/Movie/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.read_csv(f\"{data_folder}ratings.csv\").drop([\"timestamp\"], axis=1)\n",
    "movie = pd.read_csv(f\"{data_folder}movies.csv\")\n",
    "\n",
    "data = pd.merge(movie, rating, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Séparation en ligne du dataframe en petits dataframe\n",
    "N = 1000\n",
    "data_list = []\n",
    "L = data.shape[0]\n",
    "\n",
    "for i in range(1,N+1):\n",
    "    debut = int((i-1)*L/N)\n",
    "    fin = int(i*L/N)\n",
    "    data_list.append(data.iloc[debut:fin, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ac0cf1e9894c81989800e2182e435d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pivot table de chaque petits dataframe\n",
    "pv_list = []\n",
    "N = len(data_list)\n",
    "\n",
    "i = 0\n",
    "for d in tqdm(data_list):\n",
    "    pv_list.append(d.pivot_table(index=\"userId\", columns=\"title\", values=\"rating\", dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réunir tous les pivots tables selon le film\n",
    "titles = data.title.unique()\n",
    "dico = {title : [] for title in titles}\n",
    "\n",
    "for pv in pv_list:\n",
    "    for title in pv:\n",
    "        dico[title].append(pv[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9359aed3ff496bafd08644e7b3b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Concatener tous les pivots tables selon leur film et on les gardes uniquement si ils ont pas trop d'éléments manquant.\n",
    "all_df = []\n",
    "keep_title = []\n",
    "thresh = 0.3\n",
    "\n",
    "i = 0\n",
    "for title in tqdm(titles):\n",
    "    tmp = pd.concat(dico[title], axis=0)\n",
    "    if not (np.sum(tmp.isna(), axis=0) > tmp.shape[0]*thresh):\n",
    "        all_df.append(tmp)\n",
    "        keep_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On met tous les données dans un seul dataframe\n",
    "userId_title_df = pd.DataFrame(index=np.sort(data.userId.unique()), columns=keep_title)\n",
    "\n",
    "for df in tqdm(all_df):\n",
    "    index = df.index\n",
    "    values = df.values\n",
    "    title = df.name\n",
    "\n",
    "    for i in range(len(index)):\n",
    "        userId_title_df.iloc[index[i]-1][title] = values[i]\n",
    "\n",
    "userId_title_df.to_csv(f\"{data_folder}userId_title_df.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si la dataframe a déjà été exporté, on peut le récupérer localement\n",
    "if not (\"userId_title_df\" in locals()):\n",
    "    userId_title_df = pd.read_csv(f\"{data_folder}userId_title_df.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId_title_df = userId_title_df.dropna(axis=0, thresh=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Colaborative filtering\n",
    "## 4.1 - Find cluster\n",
    "### 4.1.1 - Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(row):\n",
    "    return row - np.mean(row)\n",
    "\n",
    "userId_title_std = userId_title_df.apply(standardize, axis=1).fillna(0)\n",
    "userId_title_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1f327468be44e0959bd03b3a70bdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos = cosine_similarity(userId_title_std)\n",
    "\n",
    "L = len(cos)\n",
    "cluster = {}\n",
    "\n",
    "for i in tqdm(range(L)):\n",
    "    cluster[i] = {\"+\" : [], \"-\" : []}\n",
    "    for j in range(i+1, L):\n",
    "        if (cos[i,j] >= 0.9):\n",
    "            cluster[i][\"+\"].append(j)\n",
    "        elif (cos[i,j] <= -0.9):\n",
    "            cluster[i][\"-\"].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_rate(user, title):\n",
    "    if (len(cluster[user][\"+\"]) == 0):\n",
    "        return 2.5\n",
    "    else:\n",
    "        rate = 0\n",
    "        coeff = 0\n",
    "        for u in cluster[user][\"+\"]:\n",
    "            if not (pd.isnull(userId_title_df.iloc[u][title])):\n",
    "                rate += cos[user, u]*userId_title_df.iloc[u][title]\n",
    "                coeff += cos[user, u]\n",
    "\n",
    "        if (coeff == 0):\n",
    "            return 2.5\n",
    "        else:   \n",
    "            return rate/coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.571021279177288"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_rate(11, \"Kick-Ass (2010)\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74a981a46e37d63b82983f5b77d7c74cce8983549ccfc8d083c110a6dffce6c1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
